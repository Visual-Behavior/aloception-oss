

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>Alodataset: Loading your vision datasets &mdash; Aloception 0.0.1 documentation</title>
  

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />

  
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
        <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Alonet : Training your models" href="alonet.html" />
    <link rel="prev" title="Aloscene: Computer vision with ease" href="aloscene.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home"> Aloception
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption" role="heading"><span class="caption-text">Geting Started</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="getting_started.html">Getting started</a></li>
<li class="toctree-l1"><a class="reference internal" href="aloscene.html">Aloscene: Computer vision with ease</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Alodataset: Loading your vision datasets</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#Using-samples">Using samples</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Stream-loader">Stream loader</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Train-loader">Train loader</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Using-transformations">Using transformations</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="alonet.html">Alonet : Training your models</a></li>
<li class="toctree-l1"><a class="reference internal" href="augmented_tensor.html">About augmented tensors</a></li>
<li class="toctree-l1"><a class="reference internal" href="augmented_tensor.html#Statefull-tensors">Statefull tensors</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Turorials</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/data_setup.html">How to setup your data?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/training_detr.html">Training Detr</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/finetuning_detr.html">Finetuning DETR</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/training_deformable_detr.html">Training Deformable DETR</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/finetuning_deformable_detr.html">Finetuning Deformanble DETR</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/tensort_inference.html">Exporting DETR / Deformable-DETR to TensorRT</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Aloception API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../aloscene/aloscene.html">Aloscene</a></li>
<li class="toctree-l1"><a class="reference internal" href="../alodataset/alodataset.html">Alodataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="../alonet/alonet.html">Alonet</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Aloception</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li>Alodataset: Loading your vision datasets</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="../_sources/getting_started/alodataset.ipynb.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput.container div.prompt *,
div.nboutput.container div.prompt *,
div.nbinput.container div.input_area pre,
div.nboutput.container div.output_area pre,
div.nbinput.container div.input_area .highlight,
div.nboutput.container div.output_area .highlight {
    border: none;
    padding: 0;
    margin: 0;
    box-shadow: none;
}

div.nbinput.container > div[class*=highlight],
div.nboutput.container > div[class*=highlight] {
    margin: 0;
}

div.nbinput.container div.prompt *,
div.nboutput.container div.prompt * {
    background: none;
}

div.nboutput.container div.output_area .highlight,
div.nboutput.container div.output_area pre {
    background: unset;
}

div.nboutput.container div.output_area div.highlight {
    color: unset;  /* override Pygments text color */
}

/* avoid gaps between output lines */
div.nboutput.container div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput.container,
div.nboutput.container {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput.container,
    div.nboutput.container {
        flex-direction: column;
    }
}

/* input container */
div.nbinput.container {
    padding-top: 5px;
}

/* last container */
div.nblast.container {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput.container div.prompt pre {
    color: #307FC1;
}

/* output prompt */
div.nboutput.container div.prompt pre {
    color: #BF5B3D;
}

/* all prompts */
div.nbinput.container div.prompt,
div.nboutput.container div.prompt {
    width: 4.5ex;
    padding-top: 5px;
    position: relative;
    user-select: none;
}

div.nbinput.container div.prompt > div,
div.nboutput.container div.prompt > div {
    position: absolute;
    right: 0;
    margin-right: 0.3ex;
}

@media (max-width: 540px) {
    div.nbinput.container div.prompt,
    div.nboutput.container div.prompt {
        width: unset;
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput.container div.prompt.empty {
        padding: 0;
    }

    div.nbinput.container div.prompt > div,
    div.nboutput.container div.prompt > div {
        position: unset;
    }
}

/* disable scrollbars on prompts */
div.nbinput.container div.prompt pre,
div.nboutput.container div.prompt pre {
    overflow: hidden;
}

/* input/output area */
div.nbinput.container div.input_area,
div.nboutput.container div.output_area {
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput.container div.input_area,
    div.nboutput.container div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput.container div.input_area {
    border: 1px solid #e0e0e0;
    border-radius: 2px;
    /*background: #f5f5f5;*/
}

/* override MathJax center alignment in output cells */
div.nboutput.container div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.imgmath center alignment in output cells */
div.nboutput.container div.math p {
    text-align: left;
}

/* standard error */
div.nboutput.container div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }


div.nbinput.container div.input_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight].math,
div.nboutput.container div.output_area.rendered_html,
div.nboutput.container div.output_area > div.output_javascript,
div.nboutput.container div.output_area:not(.rendered_html) > img{
    padding: 5px;
    margin: 0;
}

/* fix copybtn overflow problem in chromium (needed for 'sphinx_copybutton') */
div.nbinput.container div.input_area > div[class^='highlight'],
div.nboutput.container div.output_area > div[class^='highlight']{
    overflow-y: hidden;
}

/* hide copybtn icon on prompts (needed for 'sphinx_copybutton') */
.prompt a.copybtn {
    display: none;
}

/* Some additional styling taken form the Jupyter notebook CSS */
div.rendered_html table {
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
div.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
div.rendered_html tr,
div.rendered_html th,
div.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
div.rendered_html th {
  font-weight: bold;
}
div.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
div.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}

/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<div class="section" id="Alodataset:-Loading-your-vision-datasets">
<h1>Alodataset: Loading your vision datasets<a class="headerlink" href="#Alodataset:-Loading-your-vision-datasets" title="Permalink to this headline">¶</a></h1>
<p>Alodataset implements ready-to-use datasets for computer vision with the help of <code class="docutils literal notranslate"><span class="pre">aloscene</span></code> and augmented tensors to make it easy to transform and display your vision data. The list of all datasets can be found in the alodataset section in the aloception API.</p>
<div class="section" id="Using-samples">
<h2>Using samples<a class="headerlink" href="#Using-samples" title="Permalink to this headline">¶</a></h2>
<p>Most proposed dataset on aloception can be built using <code class="docutils literal notranslate"><span class="pre">samples=True</span></code>. It means you can at any point try out one dataset without having the data on your disk. This is great for a quick test or to quickly try out a model.</p>
<p>Here is a quick example of creating datasets using samples.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">alodataset</span>

<span class="c1"># Coco Detection Dataset</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">alodataset</span><span class="o">.</span><span class="n">CocoDetectionDataset</span><span class="p">(</span><span class="n">sample</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">frame</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">getitem</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">frame</span><span class="o">.</span><span class="n">get_view</span><span class="p">()</span><span class="o">.</span><span class="n">render</span><span class="p">()</span>

<span class="c1"># Waymo dataset</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">alodataset</span><span class="o">.</span><span class="n">WaymoDataset</span><span class="p">(</span><span class="n">sample</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="c1"># This dataset return multiple camera view</span>
<span class="n">waymo_frame</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">getitem</span><span class="p">(</span><span class="mi">0</span><span class="p">)[</span><span class="s2">&quot;front&quot;</span><span class="p">]</span>
<span class="n">waymo_frame</span><span class="o">.</span><span class="n">get_view</span><span class="p">()</span><span class="o">.</span><span class="n">render</span><span class="p">()</span>

<span class="c1"># Crowd Human dataset</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">alodataset</span><span class="o">.</span><span class="n">CrowdHumanDataset</span><span class="p">(</span><span class="n">sample</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">crowd_frame</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">getitem</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">crowd_frame</span><span class="o">.</span><span class="n">get_view</span><span class="p">()</span><span class="o">.</span><span class="n">render</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/getting_started_alodataset_3_0.png" src="../_images/getting_started_alodataset_3_0.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/getting_started_alodataset_3_1.png" src="../_images/getting_started_alodataset_3_1.png" />
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/getting_started_alodataset_3_2.png" src="../_images/getting_started_alodataset_3_2.png" />
</div>
</div>
<div class="admonition note">
<p class="admonition-title fa fa-exclamation-circle"><strong>NOTE</strong></p>
<ul class="simple">
<li><p>In the above example, getting a view on the Waymo dataset display more images since the frames are made of multiple set of boxes 2d. By default, get view will plot all the sets on different view. This is the same for the HumanCrowd dataset.</p></li>
<li><p>Since waymo is a sequence based dataset, the samples are made using with a temporal dimension. Therefore, the plot display the first (t=0) and second time step (t=1).</p></li>
</ul>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="nb">print</span><span class="p">(</span><span class="n">waymo_frame</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">waymo_frame</span><span class="o">.</span><span class="n">names</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
torch.Size([2, 3, 1280, 1920]) (&#39;T&#39;, &#39;C&#39;, &#39;H&#39;, &#39;W&#39;)
</pre></div></div>
</div>
</div>
<div class="section" id="Stream-loader">
<h2>Stream loader<a class="headerlink" href="#Stream-loader" title="Permalink to this headline">¶</a></h2>
<p>The provided dataset on aloception all exposed a <code class="docutils literal notranslate"><span class="pre">stream_loader()</span></code> method. It make particular sense for datasets with sequences. The method will iterate on the data without shuffling and without batch.</p>
<p>Here is an example:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">alodataset</span>

<span class="n">mot_dataset</span> <span class="o">=</span> <span class="n">alodataset</span><span class="o">.</span><span class="n">Mot17</span><span class="p">(</span><span class="n">sample</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">validation_sequences</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;MOT17-05&quot;</span><span class="p">])</span>

<span class="k">for</span> <span class="n">f</span><span class="p">,</span> <span class="n">frames</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">mot_dataset</span><span class="o">.</span><span class="n">stream_loader</span><span class="p">()):</span>
    <span class="n">frames</span><span class="o">.</span><span class="n">names</span>
    <span class="n">frames</span><span class="o">.</span><span class="n">get_view</span><span class="p">(</span>
        <span class="p">[</span>
            <span class="n">frames</span><span class="o">.</span><span class="n">boxes2d</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">get_view</span><span class="p">(</span><span class="n">frames</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">labels_set</span><span class="o">=</span><span class="s2">&quot;objects_class&quot;</span><span class="p">),</span>
            <span class="n">frames</span><span class="o">.</span><span class="n">boxes2d</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">get_view</span><span class="p">(</span><span class="n">frames</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">labels_set</span><span class="o">=</span><span class="s2">&quot;objects_id&quot;</span><span class="p">),</span>
        <span class="p">],</span>
        <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">700</span><span class="p">,</span> <span class="mi">1000</span><span class="p">),</span>
    <span class="p">)</span><span class="o">.</span><span class="n">render</span><span class="p">()</span>
    <span class="k">break</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/getting_started_alodataset_7_0.png" src="../_images/getting_started_alodataset_7_0.png" />
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Train-loader">
<h2>Train loader<a class="headerlink" href="#Train-loader" title="Permalink to this headline">¶</a></h2>
<p>The train loader is the one used for training or validation. The train_loader will return frames as batch (list of Frame).</p>
<p>Having a list of frame, one might want to merge all the frame on a batch dimension, even if the frames have different size. For this usual use case, all spatial augmented tensor (frames, mask, flow…) can be concat using the <code class="docutils literal notranslate"><span class="pre">batch_list</span></code> method. All augmented tensors will be padded and will expose a <code class="docutils literal notranslate"><span class="pre">mask</span></code> property keeping track of the padded area.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">alodataset</span>
<span class="kn">import</span> <span class="nn">aloscene</span>

<span class="c1"># Coco Detection Dataset</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">alodataset</span><span class="o">.</span><span class="n">CocoDetectionDataset</span><span class="p">(</span><span class="n">sample</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="k">for</span> <span class="n">frames</span> <span class="ow">in</span> <span class="n">dataset</span><span class="o">.</span><span class="n">train_loader</span><span class="p">(</span><span class="n">batch_size</span><span class="o">=</span><span class="mi">2</span><span class="p">):</span>
    <span class="n">frames</span> <span class="o">=</span> <span class="n">aloscene</span><span class="o">.</span><span class="n">Frame</span><span class="o">.</span><span class="n">batch_list</span><span class="p">(</span><span class="n">frames</span><span class="p">)</span>
    <span class="n">frames</span><span class="o">.</span><span class="n">get_view</span><span class="p">()</span><span class="o">.</span><span class="n">render</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">frames</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">frames</span><span class="o">.</span><span class="n">names</span><span class="p">)</span>
    <span class="k">break</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/getting_started_alodataset_10_0.png" src="../_images/getting_started_alodataset_10_0.png" />
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
torch.Size([2, 3, 640, 500]) (&#39;B&#39;, &#39;C&#39;, &#39;H&#39;, &#39;W&#39;)
</pre></div></div>
</div>
<p>In the above example, the two loaded images have different size. Therefore, merging the frames on the batch dimension will padd each frame, automaticly pad the boxes accordingly and add a <code class="docutils literal notranslate"><span class="pre">mask</span></code> (visible on the right) to keep track of the padded area.</p>
</div>
<div class="section" id="Using-transformations">
<h2>Using transformations<a class="headerlink" href="#Using-transformations" title="Permalink to this headline">¶</a></h2>
<p>Using the transformations provided by <code class="docutils literal notranslate"><span class="pre">alodataset</span></code>, one can very simply augment its data while being sure that all data will change accordingly. For example, in the following example, cropping, flipping and resizing the frames will automaticly update the attached boxes.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">alodataset</span> <span class="kn">import</span> <span class="n">transforms</span> <span class="k">as</span> <span class="n">T</span>
<span class="kn">import</span> <span class="nn">alodataset</span>
<span class="kn">import</span> <span class="nn">aloscene</span>

<span class="k">def</span> <span class="nf">transform_fn</span><span class="p">(</span><span class="n">frame</span><span class="p">):</span>
    <span class="n">scales</span> <span class="o">=</span> <span class="p">[</span><span class="mi">480</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="mi">544</span><span class="p">,</span> <span class="mi">576</span><span class="p">,</span> <span class="mi">608</span><span class="p">,</span> <span class="mi">640</span><span class="p">,</span> <span class="mi">672</span><span class="p">,</span> <span class="mi">704</span><span class="p">,</span> <span class="mi">736</span><span class="p">,</span> <span class="mi">768</span><span class="p">,</span> <span class="mi">800</span><span class="p">]</span>
    <span class="n">frame</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">Compose</span><span class="p">(</span>
        <span class="p">[</span>
            <span class="n">T</span><span class="o">.</span><span class="n">RandomHorizontalFlip</span><span class="p">(),</span>
            <span class="n">T</span><span class="o">.</span><span class="n">RandomSelect</span><span class="p">(</span>
                <span class="n">T</span><span class="o">.</span><span class="n">RandomResizeWithAspectRatio</span><span class="p">(</span><span class="n">scales</span><span class="p">,</span> <span class="n">max_size</span><span class="o">=</span><span class="mi">1333</span><span class="p">),</span>
                <span class="n">T</span><span class="o">.</span><span class="n">Compose</span><span class="p">(</span>
                    <span class="p">[</span>
                        <span class="n">T</span><span class="o">.</span><span class="n">RandomResizeWithAspectRatio</span><span class="p">([</span><span class="mi">400</span><span class="p">,</span> <span class="mi">500</span><span class="p">,</span> <span class="mi">600</span><span class="p">]),</span>
                        <span class="n">T</span><span class="o">.</span><span class="n">RandomSizeCrop</span><span class="p">(</span><span class="mi">384</span><span class="p">,</span> <span class="mi">600</span><span class="p">),</span>
                        <span class="n">T</span><span class="o">.</span><span class="n">RandomResizeWithAspectRatio</span><span class="p">(</span><span class="n">scales</span><span class="p">,</span> <span class="n">max_size</span><span class="o">=</span><span class="mi">1333</span><span class="p">),</span>
                    <span class="p">]</span>
                <span class="p">),</span>
            <span class="p">),</span>
        <span class="p">]</span>
    <span class="p">)(</span><span class="n">frame</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">frame</span>

<span class="c1"># Coco Detection Dataset</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">alodataset</span><span class="o">.</span><span class="n">CocoDetectionDataset</span><span class="p">(</span><span class="n">sample</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">transform_fn</span><span class="o">=</span><span class="n">transform_fn</span><span class="p">)</span>

<span class="k">for</span> <span class="n">frames</span> <span class="ow">in</span> <span class="n">dataset</span><span class="o">.</span><span class="n">train_loader</span><span class="p">(</span><span class="n">batch_size</span><span class="o">=</span><span class="mi">2</span><span class="p">):</span>
    <span class="n">frames</span> <span class="o">=</span> <span class="n">aloscene</span><span class="o">.</span><span class="n">Frame</span><span class="o">.</span><span class="n">batch_list</span><span class="p">(</span><span class="n">frames</span><span class="p">)</span>
    <span class="n">frames</span><span class="o">.</span><span class="n">get_view</span><span class="p">()</span><span class="o">.</span><span class="n">render</span><span class="p">()</span>
    <span class="k">break</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/getting_started_alodataset_14_1.png" src="../_images/getting_started_alodataset_14_1.png" />
</div>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
        <a href="alonet.html" class="btn btn-neutral float-right" title="Alonet : Training your models" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
        <a href="aloscene.html" class="btn btn-neutral float-left" title="Aloscene: Computer vision with ease" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2021, Visual Behavior.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>